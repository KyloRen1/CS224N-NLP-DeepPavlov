{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "task4_sentiment_cnn.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf23lT5B3vWd",
        "colab_type": "text"
      },
      "source": [
        "## Assignment 2.4: Text classification via CNN (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1_xAwmw3vWg",
        "colab_type": "text"
      },
      "source": [
        "In this assignment you should perform sentiment analysis of the IMDB reviews based on CNN architecture. Read carefully [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/pdf/1408.5882.pdf) by Yoon Kim."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdBFO2np3vWj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72413aae-32d2-4976-93ae-c6218907805b"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext import datasets, data\n",
        "from torchtext.data import Field, LabelField\n",
        "from torchtext.data import Iterator\n",
        "import torch\n",
        "torch.manual_seed(42)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f805bd3b8f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GOE2NTm3vWo",
        "colab_type": "text"
      },
      "source": [
        "### Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGXOAfDH3vWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = Field(sequential=True, lower=True, batch_first=True)\n",
        "LABEL = LabelField(batch_first=True, dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMTXSGaX3vWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, tst = datasets.IMDB.splits(TEXT, LABEL)\n",
        "trn, vld = train.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMCY_gFB3vWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%time\n",
        "TEXT.build_vocab(trn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5_ZA0nk3vWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL.build_vocab(trn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bEbxi-83vW2",
        "colab_type": "text"
      },
      "source": [
        "### Creating the Iterator (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiz5th_Y3vW3",
        "colab_type": "text"
      },
      "source": [
        "Define an iterator here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmpLwpiF3vW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "    (trn, vld, tst),\n",
        "    batch_size= 64,\n",
        "    device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVTLTJObU_wb",
        "colab_type": "code",
        "outputId": "1217de81-4d8a-4f17-ebb0-18a30e4db37d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "batch = next(train_iter.__iter__()); batch.text, batch.label, batch.label.type()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[146,  23, 270,  ...,   1,   1,   1],\n",
              "         [279, 104, 182,  ...,   1,   1,   1],\n",
              "         [  9,  62, 101,  ...,   1,   1,   1],\n",
              "         ...,\n",
              "         [ 15, 195,  15,  ...,   1,   1,   1],\n",
              "         [ 10,  20,   7,  ...,   1,   1,   1],\n",
              "         [ 10,   7,   2,  ...,   1,   1,   1]], device='cuda:0'),\n",
              " tensor([0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
              "         0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
              "         0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
              "         1., 0., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0'),\n",
              " 'torch.cuda.FloatTensor')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agRRwvAR3vW8",
        "colab_type": "text"
      },
      "source": [
        "### Define CNN-based text classification model (8 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3rn7jY43vW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, V, D, kernel_sizes, dropout=0.5):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings = V,\n",
        "            embedding_dim = dim\n",
        "        )\n",
        "\n",
        "        self.conv_0 = nn.Conv2d(\n",
        "            in_channels = 1,\n",
        "            out_channels = 5,\n",
        "            kernel_size = (kernel_sizes[0], dim)\n",
        "        )\n",
        "\n",
        "        self.conv_1 = nn.Conv2d(\n",
        "            in_channels = 1,\n",
        "            out_channels = 5,\n",
        "            kernel_size = (kernel_sizes[1], dim)\n",
        "        )\n",
        "\n",
        "        self.conv_2 = nn.Conv2d(\n",
        "            in_channels = 1,\n",
        "            out_channels = 5,\n",
        "            kernel_size = (kernel_sizes[2], dim)\n",
        "        )\n",
        "        self.fc = nn.Linear(len(kernel_sizes) * 5, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "      embedded = self.embedding(x).unsqueeze(1)\n",
        "\n",
        "      conv_0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
        "      conv_1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
        "      conv_2 = F.relu(self.conv_2(embedded).squeeze(3))\n",
        "\n",
        "      pool_0 = F.max_pool1d(conv_0, conv_0.shape[2]).squeeze(2)\n",
        "      pool_1 = F.max_pool1d(conv_1, conv_1.shape[2]).squeeze(2)\n",
        "      pool_2 = F.max_pool1d(conv_2, conv_2.shape[2]).squeeze(2)\n",
        "\n",
        "      cat = self.dropout(torch.cat((pool_0, pool_1, pool_2), dim=1))\n",
        "      logit = self.fc(cat)\n",
        "      return logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVhAd9Et3vW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernel_sizes = [3,4,5]\n",
        "vocab_size = len(TEXT.vocab)\n",
        "dropout = 0.5\n",
        "dim = 300\n",
        "\n",
        "model = CNN(vocab_size, dim, kernel_sizes, dropout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxj2Biqm3vXC",
        "colab_type": "code",
        "outputId": "66471e42-9e90-468f-ac6f-7e768ab2c937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "model.cuda()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (embedding): Embedding(201912, 300)\n",
              "  (conv_0): Conv2d(1, 5, kernel_size=(3, 300), stride=(1, 1))\n",
              "  (conv_1): Conv2d(1, 5, kernel_size=(4, 300), stride=(1, 1))\n",
              "  (conv_2): Conv2d(1, 5, kernel_size=(5, 300), stride=(1, 1))\n",
              "  (fc): Linear(in_features=15, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN1Tl6rQ3vXF",
        "colab_type": "text"
      },
      "source": [
        "### The training loop (3 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFhB60GA3vXG",
        "colab_type": "text"
      },
      "source": [
        "Define the optimization function and the loss functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWYfo9kG3vXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = optim.Adam(model.parameters()) \n",
        "loss_func = nn.BCEWithLogitsLoss() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2f7PI7r3vXJ",
        "colab_type": "text"
      },
      "source": [
        "Think carefully about the stopping criteria. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9kw5FCB3vXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10 # your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WpJWL6Q3vXM",
        "colab_type": "code",
        "outputId": "fb23aef3-2901-4a94-8e19-61c7c3b1782d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "%%time\n",
        "for epoch in range(1, epochs + 1):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    model.train() \n",
        "    \n",
        "    for batch in train_iter:  \n",
        "  \n",
        "        opt.zero_grad()\n",
        "        preds = model(batch.text).squeeze(1)\n",
        "\n",
        "        loss = loss_func(preds, batch.label)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    epoch_loss = running_loss / len(trn)\n",
        "    \n",
        "    val_loss = 0.0\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0 \n",
        "    for batch in val_iter:\n",
        "\n",
        "        preds = model(batch.text).squeeze(1)\n",
        "        loss = loss_func(preds, batch.label)\n",
        "        val_loss += loss.item()\n",
        "        \n",
        "    val_loss /= len(vld)\n",
        "    \n",
        "    print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, epoch_loss, val_loss))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training Loss: 0.010962334643091475, Validation Loss: 0.009320342071851095\n",
            "Epoch: 2, Training Loss: 0.009587648372990745, Validation Loss: 0.008643218803405761\n",
            "Epoch: 3, Training Loss: 0.008896584039075034, Validation Loss: 0.008106801501909892\n",
            "Epoch: 4, Training Loss: 0.008237763113634926, Validation Loss: 0.007815456879138946\n",
            "Epoch: 5, Training Loss: 0.007501480575970241, Validation Loss: 0.007354682270685832\n",
            "Epoch: 6, Training Loss: 0.006472509408848626, Validation Loss: 0.006976891314983368\n",
            "Epoch: 7, Training Loss: 0.005445533606835774, Validation Loss: 0.006978283977508545\n",
            "Epoch: 8, Training Loss: 0.004376371955871582, Validation Loss: 0.007098943030834198\n",
            "Epoch: 9, Training Loss: 0.003514788212946483, Validation Loss: 0.007374733328819275\n",
            "Epoch: 10, Training Loss: 0.0029060147268431527, Validation Loss: 0.0078299218416214\n",
            "CPU times: user 1min 29s, sys: 37.7 s, total: 2min 7s\n",
            "Wall time: 2min 7s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SktZ4rJG3vXN",
        "colab_type": "text"
      },
      "source": [
        "### Calculate performance of the trained model (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-GGmoda3vXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array([])\n",
        "y_true = np.array([])\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_iter:\n",
        "        preds = model(batch.text).squeeze(1)\n",
        "        preds = torch.round(torch.sigmoid(preds))\n",
        "        predictions = np.append(predictions, preds.cpu().data.numpy())\n",
        "        y_true = np.append(y_true, batch.label.cpu().data.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fVscrcM7jLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "def metrics_report(true_y, preds_y):\n",
        "    accuracy = accuracy_score(true_y, preds_y)\n",
        "    precision = precision_score(true_y, preds_y)\n",
        "    recall = recall_score(true_y, preds_y)\n",
        "    f1 = f1_score(true_y, preds_y)\n",
        "    return accuracy, precision, recall, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvWWmBSD7k98",
        "colab_type": "code",
        "outputId": "c40a1482-493a-4130-ddc1-95379ce5e6ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "accuracy, precision, recall, f1 = metrics_report(y_true, predictions)\n",
        "print('Accuracy  ', accuracy)\n",
        "print('Precision ', precision)\n",
        "print('Recall    ', recall)\n",
        "print('F1        ', f1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy   0.78924\n",
            "Precision  0.8091492090637025\n",
            "Recall     0.75704\n",
            "F1         0.7822277330026866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rj7wiZR3vXQ",
        "colab_type": "text"
      },
      "source": [
        "Write down the calculated performance\n",
        "\n",
        "### Accuracy   0.78924\n",
        "### Precision  0.8091492090637025\n",
        "### Recall     0.75704\n",
        "### F1         0.7822277330026866"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV8geR1M_MEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del model\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBNz8myO3vXQ",
        "colab_type": "text"
      },
      "source": [
        "### Experiments (5 points)\n",
        "\n",
        "Experiment with the model and achieve better results. Implement and describe your experiments in details, mention what was helpful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiisPokA8YMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, V, D, kernel_sizes, dropout=0.5):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings = V,\n",
        "            embedding_dim = dim\n",
        "        )\n",
        "\n",
        "        self.conv_0 = nn.Conv2d(\n",
        "            in_channels = 1,\n",
        "            out_channels = 5,\n",
        "            kernel_size = (kernel_sizes[0], dim)\n",
        "        )\n",
        "\n",
        "        self.conv_1 = nn.Conv2d(\n",
        "            in_channels = 1,\n",
        "            out_channels = 5,\n",
        "            kernel_size = (kernel_sizes[1], dim)\n",
        "        )\n",
        "\n",
        "        self.conv_2 = nn.Conv2d(\n",
        "            in_channels = 1,\n",
        "            out_channels = 5,\n",
        "            kernel_size = (kernel_sizes[2], dim)\n",
        "        )\n",
        "        self.conv_3 = nn.Conv2d(\n",
        "            in_channels = 1,\n",
        "            out_channels = 5,\n",
        "            kernel_size = (kernel_sizes[3], dim)\n",
        "        )\n",
        "        self.fc = nn.Linear(len(kernel_sizes) * 5, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "      embedded = self.embedding(x).unsqueeze(1)\n",
        "\n",
        "      conv_0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
        "      conv_1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
        "      conv_2 = F.relu(self.conv_2(embedded).squeeze(3))\n",
        "      conv_3 = F.relu(self.conv_3(embedded).squeeze(3))\n",
        "\n",
        "      pool_0 = F.max_pool1d(conv_0, conv_0.shape[2]).squeeze(2)\n",
        "      pool_1 = F.max_pool1d(conv_1, conv_1.shape[2]).squeeze(2)\n",
        "      pool_2 = F.max_pool1d(conv_2, conv_2.shape[2]).squeeze(2)\n",
        "      pool_3 = F.max_pool1d(conv_3, conv_3.shape[2]).squeeze(2)\n",
        "\n",
        "      cat = self.dropout(torch.cat((pool_0, pool_1, pool_2, pool_3), dim=1))\n",
        "      logit = self.fc(cat)\n",
        "      return logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9mbTJU0_pfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernel_sizes = [3, 4, 4, 5]\n",
        "vocab_size = len(TEXT.vocab)\n",
        "dropout = 0.2\n",
        "dim = 256\n",
        "\n",
        "model = CNN(vocab_size, dim, kernel_sizes, dropout).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ62klKd_tVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = optim.Adam(model.parameters(), lr=0.001) \n",
        "loss_func = nn.BCEWithLogitsLoss() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qilnszv_0JL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 5 # your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnTMPzN__16k",
        "colab_type": "code",
        "outputId": "4fe18e78-3c40-41e4-d23b-36fc59f10ab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "%%time\n",
        "for epoch in range(1, epochs + 1):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    model.train() \n",
        "    \n",
        "    for batch in train_iter:  \n",
        "  \n",
        "        opt.zero_grad()\n",
        "        preds = model(batch.text).squeeze(1)\n",
        "\n",
        "        loss = loss_func(preds, batch.label)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    epoch_loss = running_loss / len(trn)\n",
        "    \n",
        "    val_loss = 0.0\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0 \n",
        "    for batch in val_iter:\n",
        "\n",
        "        preds = model(batch.text).squeeze(1)\n",
        "        loss = loss_func(preds, batch.label)\n",
        "        val_loss += loss.item()\n",
        "        \n",
        "    val_loss /= len(vld)\n",
        "    \n",
        "    print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, epoch_loss, val_loss))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training Loss: 0.009676512670516968, Validation Loss: 0.008033390537897745\n",
            "Epoch: 2, Training Loss: 0.007966688586984362, Validation Loss: 0.007282228211561839\n",
            "Epoch: 3, Training Loss: 0.006897969649519239, Validation Loss: 0.006823840236663818\n",
            "Epoch: 4, Training Loss: 0.005906678419453757, Validation Loss: 0.006308831483125687\n",
            "Epoch: 5, Training Loss: 0.004730303029503141, Validation Loss: 0.006111744662125905\n",
            "CPU times: user 44.4 s, sys: 17.7 s, total: 1min 2s\n",
            "Wall time: 1min 2s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZmXaSWj_3-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array([])\n",
        "y_true = np.array([])\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_iter:\n",
        "        preds = model(batch.text).squeeze(1)\n",
        "        preds = torch.round(torch.sigmoid(preds))\n",
        "        predictions = np.append(predictions, preds.cpu().data.numpy())\n",
        "        y_true = np.append(y_true, batch.label.cpu().data.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5ML1jE0_5lX",
        "colab_type": "code",
        "outputId": "4f8b50f5-3e84-4b41-a9ce-565f04d8ad02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "accuracy, precision, recall, f1 = metrics_report(y_true, predictions)\n",
        "print('Accuracy  ', accuracy)\n",
        "print('Precision ', precision)\n",
        "print('Recall    ', recall)\n",
        "print('F1        ', f1)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy   0.82148\n",
            "Precision  0.8121649965043114\n",
            "Recall     0.8364\n",
            "F1         0.8241043629054506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpaPMxcl3vXR",
        "colab_type": "text"
      },
      "source": [
        "### 1. Changed kernel size to [3, 4, 4] and hidden dim to 256. Trained for 10 epochs.\n",
        "\n",
        "Accuracy   0.80488\n",
        "\n",
        "Precision  0.811152841280209\n",
        "\n",
        "Recall     0.7948\n",
        "\n",
        "F1         0.8028931630838857\n",
        "\n",
        "### 2. Added 1 more conv filter [3, 4, 4, 5] with hidden dim 256. Trained for 5 epochs \n",
        "\n",
        "Accuracy   0.82148\n",
        "\n",
        "Precision  0.8121649965043114\n",
        "\n",
        "Recall     0.8364\n",
        "\n",
        "F1         0.8241043629054506"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrbnn58TBclT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}