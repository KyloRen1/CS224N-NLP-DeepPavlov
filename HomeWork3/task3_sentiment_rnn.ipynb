{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "task3_sentiment_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S8TcBDd6dLP",
        "colab_type": "text"
      },
      "source": [
        "## Assignment 2.3: Text classification via RNN (30 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EqfMtCh6dLS",
        "colab_type": "text"
      },
      "source": [
        "In this assignment you will perform sentiment analysis of the IMDBs reviews by using RNN. An additional goal is to learn high abstactions of the **torchtext** module that consists of data processing utilities and popular datasets for natural language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7Q3gFf96dLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torchtext import datasets\n",
        "\n",
        "from torchtext.data import Field, LabelField\n",
        "from torchtext.data import BucketIterator\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYpkBV8T6dLc",
        "colab_type": "text"
      },
      "source": [
        "### Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwz3Gx736dLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = Field(sequential=True, lower=True)\n",
        "LABEL = LabelField(dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVsNArCO6dLi",
        "colab_type": "code",
        "outputId": "58a44507-00db-4ee0-a30f-b65c2f44042e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train, tst = datasets.IMDB.splits(TEXT, LABEL)\n",
        "trn, vld = train.split()\n",
        "print(len(trn))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gITTeRl86dLl",
        "colab_type": "code",
        "outputId": "d22b6f66-cfa5-4387-a5a9-bb068fb7d1b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "MAX_VOCAB_SIZE = 25000\n",
        "TEXT.build_vocab(trn, max_size = MAX_VOCAB_SIZE)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.1 s, sys: 22 ms, total: 1.12 s\n",
            "Wall time: 1.13 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9axJQfB6dLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL.build_vocab(trn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qARzyNn6dLs",
        "colab_type": "text"
      },
      "source": [
        "The vocab.freqs is a collections.Counter object, so we can take a look at the most frequent words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnpG7dff6dLs",
        "colab_type": "code",
        "outputId": "e408e9a1-b0d6-4d7c-84ab-db13e1de85ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "TEXT.vocab.freqs.most_common(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 225207),\n",
              " ('a', 111530),\n",
              " ('and', 110502),\n",
              " ('of', 101129),\n",
              " ('to', 93533),\n",
              " ('is', 72659),\n",
              " ('in', 63316),\n",
              " ('i', 49352),\n",
              " ('this', 48818),\n",
              " ('that', 46311)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdILRJpR6dLv",
        "colab_type": "text"
      },
      "source": [
        "### Creating the Iterator (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnL21P9A6dLw",
        "colab_type": "text"
      },
      "source": [
        "During training, we'll be using a special kind of Iterator, called the **BucketIterator**. When we pass data into a neural network, we want the data to be padded to be the same length so that we can process them in batch:\n",
        "\n",
        "e.g.\n",
        "\\[ \n",
        "\\[3, 15, 2, 7\\],\n",
        "\\[4, 1\\], \n",
        "\\[5, 5, 6, 8, 1\\] \n",
        "\\] -> \\[ \n",
        "\\[3, 15, 2, 7, **0**\\],\n",
        "\\[4, 1, **0**, **0**, **0**\\], \n",
        "\\[5, 5, 6, 8, 1\\] \n",
        "\\] \n",
        "\n",
        "If the sequences differ greatly in length, the padding will consume a lot of wasteful memory and time. The BucketIterator groups sequences of similar lengths together for each batch to minimize padding.\n",
        "\n",
        "Complete the definition of the **BucketIterator** object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_a2bKi56dLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
        "        (trn, vld, tst),\n",
        "        batch_size= 64,\n",
        "        sort=False,\n",
        "        sort_key=lambda x: len(x.comment_text), # write your code here\n",
        "        sort_within_batch=False,\n",
        "        device=device,\n",
        "        repeat=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8T6R_EZ6dLz",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at what the output of the BucketIterator looks like. Do not be suprised **batch_first=True**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epeAA4hO6dL0",
        "colab_type": "code",
        "outputId": "4bd387d2-98a5-45c0-fc91-40661d2dacd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "batch = next(train_iter.__iter__()); batch.text"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    0, 11878,  8688,  ...,  7889,  7306,    23],\n",
              "        [    0,   347, 15642,  ...,    30,  9080,     6],\n",
              "        [    3,   102,     7,  ...,     5,    14,    28],\n",
              "        ...,\n",
              "        [    1,     1,     1,  ...,     1,     1,     1],\n",
              "        [    1,     1,     1,  ...,     1,     1,     1],\n",
              "        [    1,     1,     1,  ...,     1,     1,     1]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE80sA436dL2",
        "colab_type": "text"
      },
      "source": [
        "The batch has all the fields we passed to the Dataset as attributes. The batch data can be accessed through the attribute with the same name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO6vLaK86dL2",
        "colab_type": "code",
        "outputId": "46de621c-cb55-4331-91dc-4c1ae5658eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch.__dict__.keys()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['batch_size', 'dataset', 'fields', 'input_fields', 'target_fields', 'text', 'label'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn4LsFoO6dL4",
        "colab_type": "text"
      },
      "source": [
        "### Define the RNN-based text classification model (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK7HbGTa6dL4",
        "colab_type": "text"
      },
      "source": [
        "Start simple first. Implement the model according to the shema below.  \n",
        "![alt text](https://miro.medium.com/max/1396/1*v-tLYQCsni550A-hznS0mw.jpeg)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxW59rAZ6dL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNBaseline(nn.Module):\n",
        "    def __init__(self, hidden_dim, emb_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=len(TEXT.vocab), \n",
        "            embedding_dim=emb_dim,\n",
        "            )\n",
        "        \n",
        "        self.gru = nn.GRU(\n",
        "            input_size=emb_dim, \n",
        "            hidden_size=hidden_dim\n",
        "            )\n",
        "        \n",
        "        self.fc = nn.Linear(\n",
        "            in_features=hidden_dim, \n",
        "            out_features = 1\n",
        "            )\n",
        "            \n",
        "    def forward(self, seq):\n",
        "        # seq = [text_len, batch_size]\n",
        "\n",
        "        embedded = self.embedding(seq)\n",
        "        # embedded = [text_len, batch_size, embed_dim]\n",
        "\n",
        "        output, hidden = self.gru(embedded)\n",
        "        # output = [text_len, batch_size, hid_dim]\n",
        "        # hidden = [1, batch_size, hid_dim]\n",
        "\n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "\n",
        "        preds = self.fc(hidden.squeeze(0))\n",
        "        return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1MplGqJ6dL7",
        "colab_type": "code",
        "outputId": "05e8e738-0b60-4dac-ea54-73785b20b3df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "em_sz = 200\n",
        "nh = 300\n",
        "model = RNNBaseline(nh, emb_dim=em_sz); model"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNBaseline(\n",
              "  (embedding): Embedding(25002, 200)\n",
              "  (gru): GRU(200, 300)\n",
              "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsyTUqZS6dL8",
        "colab_type": "text"
      },
      "source": [
        "If you're using a GPU, remember to call model.cuda() to move your model to the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUpKh6fd6dL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S5U69HQ6dL-",
        "colab_type": "text"
      },
      "source": [
        "### The training loop (3 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY9FX0cJ6dL_",
        "colab_type": "text"
      },
      "source": [
        "Define the optimization and the loss functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pNGCCPx6dL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = optim.Adam(model.parameters(), lr=1e-3) \n",
        "loss_func = nn.BCEWithLogitsLoss().to(device) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7KKn3_66dMB",
        "colab_type": "text"
      },
      "source": [
        "Define the stopping criteria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIXPh1wF6dMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 5 # your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTRKhcZE6dMD",
        "colab_type": "code",
        "outputId": "066c9c60-3c39-4fc0-f478-d33e19813a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "%%time\n",
        "for epoch in range(1, epochs + 1):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    model.train() \n",
        "    for batch in train_iter: \n",
        "\n",
        "        opt.zero_grad()\n",
        "        preds = model(batch.text).squeeze(1) \n",
        "        loss = loss_func(preds, batch.label)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(trn)\n",
        "    \n",
        "    val_loss = 0.0\n",
        "    model.eval()\n",
        "    for batch in val_iter:\n",
        "        \n",
        "        preds = model(batch.text).squeeze(1) \n",
        "        loss = loss_func(preds, batch.label)\n",
        "        val_loss += loss.item()\n",
        "        \n",
        "    val_loss /= len(vld)\n",
        "    print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, epoch_loss, val_loss))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training Loss: 0.010980496900422233, Validation Loss: 0.010902446150779723\n",
            "Epoch: 2, Training Loss: 0.010882041849408832, Validation Loss: 0.010913486154874166\n",
            "Epoch: 3, Training Loss: 0.010845106482505798, Validation Loss: 0.010769179232915243\n",
            "Epoch: 4, Training Loss: 0.008927319971152715, Validation Loss: 0.006545571482181549\n",
            "Epoch: 5, Training Loss: 0.004724217485530036, Validation Loss: 0.005722816616296768\n",
            "CPU times: user 1min 55s, sys: 28.9 s, total: 2min 24s\n",
            "Wall time: 2min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KH-Pq7-6dMF",
        "colab_type": "text"
      },
      "source": [
        "### Calculate performance of the trained model (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxn1dy1v6dMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array([])\n",
        "y_true = np.array([])\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_iter:\n",
        "        preds = model(batch.text).squeeze(1)\n",
        "        preds = torch.round(torch.sigmoid(preds))\n",
        "        predictions = np.append(predictions, preds.cpu().data.numpy())\n",
        "        y_true = np.append(y_true, batch.label.cpu().data.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n-3_s4NqmJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "def metrics_report(true_y, preds_y):\n",
        "    accuracy = accuracy_score(true_y, preds_y)\n",
        "    precision = precision_score(true_y, preds_y)\n",
        "    recall = recall_score(true_y, preds_y)\n",
        "    f1 = f1_score(true_y, preds_y)\n",
        "    return accuracy, precision, recall, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSxqiZ4DrU0G",
        "colab_type": "code",
        "outputId": "c91016cf-d314-47a1-8b57-a8d672656596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "accuracy, precision, recall, f1 = metrics_report(y_true, predictions)\n",
        "print('Accuracy  ', accuracy)\n",
        "print('Precision ', precision)\n",
        "print('Recall    ', recall)\n",
        "print('F1        ', f1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy   0.83908\n",
            "Precision  0.921783262016121\n",
            "Recall     0.74104\n",
            "F1         0.8215885405117743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJAhhXmf6dMI",
        "colab_type": "text"
      },
      "source": [
        "Write down the calculated performance\n",
        "\n",
        "### Accuracy   0.828\n",
        "### Precision  0.894990366088632\n",
        "### Recall     0.7432\n",
        "### F1         0.8120629370629371"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaH0y92PcKYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del model\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLi0WFSK6dMI",
        "colab_type": "text"
      },
      "source": [
        "### Experiments (10 points)\n",
        "\n",
        "Experiment with the model and achieve better results. You can find advices [here](https://arxiv.org/abs/1801.06146). Implement and describe your experiments in details, mention what was helpful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GaFRjL1QMah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, hidden_dim, emb_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=len(TEXT.vocab), \n",
        "            embedding_dim=emb_dim,\n",
        "            )\n",
        "        \n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=emb_dim, \n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=2,\n",
        "            bidirectional=True,\n",
        "            dropout=0.2\n",
        "            )\n",
        "        self.lstm_2 = nn.LSTM(\n",
        "            input_size=hidden_dim*2,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=2,\n",
        "            bidirectional=True,\n",
        "            dropout=0.2\n",
        "            )\n",
        "        self.fc = nn.Linear(\n",
        "            in_features=hidden_dim * 2, \n",
        "            out_features = 1\n",
        "            )\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "            \n",
        "    def forward(self, seq):\n",
        "        embedded = self.embedding(seq)\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        output, (hidden, cell) = self.lstm_2(output)\n",
        "        hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
        "        preds = self.fc(hidden)\n",
        "        return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY1igHPeT5-t",
        "colab_type": "code",
        "outputId": "489e4c3d-c69c-47b9-f9d7-d5307e4d0331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "em_sz = 100\n",
        "nh = 256\n",
        "model = RNN(nh, emb_dim=em_sz); model"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(25002, 100)\n",
              "  (lstm): LSTM(100, 256, num_layers=2, dropout=0.2, bidirectional=True)\n",
              "  (lstm_2): LSTM(512, 256, num_layers=2, dropout=0.2, bidirectional=True)\n",
              "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiPLoaU-UDDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)\n",
        "\n",
        "opt = optim.Adam(model.parameters(), lr=1e-3) \n",
        "loss_func = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "epochs = 7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvYIMRM3UILk",
        "colab_type": "code",
        "outputId": "eee120b8-c8f4-4036-970e-b9c938b8d4e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "%%time\n",
        "for epoch in range(1, epochs + 1):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    model.train() \n",
        "    for batch in train_iter: \n",
        "\n",
        "        opt.zero_grad()\n",
        "        preds = model(batch.text).squeeze(1) \n",
        "        loss = loss_func(preds, batch.label)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(trn)\n",
        "    \n",
        "    val_loss = 0.0\n",
        "    model.eval()\n",
        "    for batch in val_iter:\n",
        "        \n",
        "        preds = model(batch.text).squeeze(1) \n",
        "        loss = loss_func(preds, batch.label)\n",
        "        val_loss += loss.item()\n",
        "        \n",
        "    val_loss /= len(vld)\n",
        "    print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, epoch_loss, val_loss))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training Loss: 0.010666684733118329, Validation Loss: 0.010889897274971009\n",
            "Epoch: 2, Training Loss: 0.009524216517380306, Validation Loss: 0.009167809947331747\n",
            "Epoch: 3, Training Loss: 0.008454268496377128, Validation Loss: 0.007150847907861074\n",
            "Epoch: 4, Training Loss: 0.006180550186974661, Validation Loss: 0.00610453633069992\n",
            "Epoch: 5, Training Loss: 0.0045721262037754055, Validation Loss: 0.005529360460241635\n",
            "Epoch: 6, Training Loss: 0.004056513360994203, Validation Loss: 0.005276496680577596\n",
            "Epoch: 7, Training Loss: 0.0031857222161122732, Validation Loss: 0.005711840677261352\n",
            "CPU times: user 22min 22s, sys: 7min 50s, total: 30min 13s\n",
            "Wall time: 30min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ2GvUiNW5vE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array([])\n",
        "y_true = np.array([])\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_iter:\n",
        "        preds = model(batch.text).squeeze(1)\n",
        "        preds = torch.round(torch.sigmoid(preds))\n",
        "        predictions = np.append(predictions, preds.cpu().data.numpy())\n",
        "        y_true = np.append(y_true, batch.label.cpu().data.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUNBRQOBuMgh",
        "colab_type": "code",
        "outputId": "52b9e4db-cf2b-4301-e108-e64e98c7dd17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "accuracy, precision, recall, f1 = metrics_report(y_true, predictions)\n",
        "print('Accuracy  ', accuracy)\n",
        "print('Precision ', precision)\n",
        "print('Recall    ', recall)\n",
        "print('F1        ', f1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy   0.8546\n",
            "Precision  0.8733260338583341\n",
            "Recall     0.82952\n",
            "F1         0.8508595577072992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST5sLFMZ6dMJ",
        "colab_type": "text"
      },
      "source": [
        "### 1. Tried bidirectional LSTM and trained for 5 epochs with Dropout of 0.2 Obtained: \n",
        "Accuracy   0.85144\n",
        "\n",
        "Precision  0.8706547418157273\n",
        "\n",
        "Recall     0.82552\n",
        "\n",
        "F1         0.8474868593955323\n",
        "\n",
        "### 2. Tried bidirectional Two layer LSTM and trained for 7 epochs with Dropout 0.2 Obtained:\n",
        "\n",
        "Accuracy   0.8546\n",
        "\n",
        "Precision  0.8733260338583341\n",
        "\n",
        "Recall     0.82952\n",
        "\n",
        "F1         0.8508595577072992\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fm0fWMhCGL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}